{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Manipulating Geospatial Data",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pardeshigithub/GIS-System/blob/main/Manipulating_Geospatial_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'geospatial-learn-course-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F348259%2F695175%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240306%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240306T143902Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0cb4bd9446dabb61e7abcdf55c102963ef5d7710ef1a13c7ebdca8df6a81d32a8beac2bd52668695ac4406bdfc20bb2d45b4a5693a4720a50536529f7aae6a1313cff361962145f2097a5c615bea6acc66cdbef1733702ff842997687c2e2f8072c0e4a79ccea55f7277cfc12445fbffd640a922afda08bc1aa7de782e24e2eae5b96d04ac71e621ef280bb715f35732caca7e728071301391d0b5f07743bdaf33ff587ec109f80e1877b4fc3bab10561112ed59e966261fd1e386984dd5b9340dfd5b08ceb5764fd0bb26cf1d498b61932e05bb84764b697e2c943448e45146ed28960b3fc55fa6e3e9edfc886e874abaa39433413a37bf7a609071e97872be,data-for-datavis:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F116573%2F3551030%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240306%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240306T143902Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D89bf65c8bf6ceea7456ea66ecde0c70628c6e7624eaa12c41f4c7d1de09c59bfc4f1a0d4d2d5bab50a281639a5420e9ef3bf1ffbd54640923e12bbcac1dcefd75e02a2bc808b8541f455e7c7558bc7ca4ae762074032beec2e392b3872a59b32157c8b86fd661d2c46c75102321909c0f3b78285997ada57585ce25de0a733e2ceddf8b6bef9a6d457814d5450e57397283ff63210668f5c3473c434bb89417276a459b02207dd8c7d683502f19315697e450e5729a968a82ae1c9b11b0b11fac2636fdb010455992c2b1550cc169982b3451091196a7a287052479bbea1999a64dac67a6bbf0b293414dc57bed377b15c09832eb90f81517299c91235715406'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "uTMdZZfTNDMV"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this tutorial, you'll learn about two common manipulations for geospatial data: **geocoding** and **table joins**."
      ],
      "metadata": {
        "id": "XHtAwVA7NDMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import folium\n",
        "from folium import Marker\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-04-20T21:30:40.445103Z",
          "iopub.execute_input": "2023-04-20T21:30:40.446304Z",
          "iopub.status.idle": "2023-04-20T21:30:41.394379Z",
          "shell.execute_reply.started": "2023-04-20T21:30:40.446257Z",
          "shell.execute_reply": "2023-04-20T21:30:41.393238Z"
        },
        "trusted": true,
        "id": "TxetmRWCNDMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geocoding\n",
        "\n",
        "**Geocoding** is the process of converting the name of a place or an address to a location on a map.  If you have ever looked up a geographic location based on a landmark description with [Google Maps](https://www.google.com/maps), [Bing Maps](https://www.bing.com/maps), or [Baidu Maps](https://map.baidu.com/), for instance, then you have used a geocoder!\n",
        "\n",
        "![](https://storage.googleapis.com/kaggle-media/learn/images/1IrgZQq.png)\n",
        "\n",
        "We'll use geopy to do all of our geocoding."
      ],
      "metadata": {
        "id": "47Id9beTNDMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.geocoders import Nominatim"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-20T21:30:41.396208Z",
          "iopub.execute_input": "2023-04-20T21:30:41.396788Z",
          "iopub.status.idle": "2023-04-20T21:30:41.605972Z",
          "shell.execute_reply.started": "2023-04-20T21:30:41.396751Z",
          "shell.execute_reply": "2023-04-20T21:30:41.604911Z"
        },
        "trusted": true,
        "id": "VBTBNH_pNDMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code cell above, [`Nominatim`](https://nominatim.openstreetmap.org/) refers to the geocoding software that will be used to generate locations.\n",
        "\n",
        "We begin by instantiating the geocoder.  Then, we need only apply the name or address as a Python string. (In this case, we supply `\"Pyramid of Khufu\"`, also known as the Great Pyramid of Giza.)\n",
        "\n",
        "If the geocoding is successful, it returns a `geopy.location.Location` object with two important attributes:\n",
        "- the \"point\" attribute contains the (latitude, longitude) location, and\n",
        "- the \"address\" attribute contains the full address."
      ],
      "metadata": {
        "id": "UKQSLi0eNDMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "geolocator = Nominatim(user_agent=\"kaggle_learn\")\n",
        "location = geolocator.geocode(\"Pyramid of Khufu\")\n",
        "\n",
        "print(location.point)\n",
        "print(location.address)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-20T21:30:41.607489Z",
          "iopub.execute_input": "2023-04-20T21:30:41.608063Z",
          "iopub.status.idle": "2023-04-20T21:30:42.507025Z",
          "shell.execute_reply.started": "2023-04-20T21:30:41.60802Z",
          "shell.execute_reply": "2023-04-20T21:30:42.506002Z"
        },
        "trusted": true,
        "id": "deRbsbE0NDMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value for the \"point\" attribute is a `geopy.point.Point` object, and we can get the latitude and longitude from the `latitude` and `longitude` attributes, respectively."
      ],
      "metadata": {
        "id": "EfMKQJuaNDMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "point = location.point\n",
        "print(\"Latitude:\", point.latitude)\n",
        "print(\"Longitude:\", point.longitude)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-20T21:30:42.508962Z",
          "iopub.execute_input": "2023-04-20T21:30:42.509311Z",
          "iopub.status.idle": "2023-04-20T21:30:42.515195Z",
          "shell.execute_reply.started": "2023-04-20T21:30:42.509277Z",
          "shell.execute_reply": "2023-04-20T21:30:42.514287Z"
        },
        "trusted": true,
        "id": "K0ItxzV4NDMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's often the case that we'll need to geocode many different addresses.  For instance, say we want to obtain the locations of 100 top universities in Europe."
      ],
      "metadata": {
        "id": "sTcnXujcNDMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "universities = pd.read_csv(\"../input/geospatial-learn-course-data/top_universities.csv\")\n",
        "universities.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-20T21:30:42.516484Z",
          "iopub.execute_input": "2023-04-20T21:30:42.517547Z",
          "iopub.status.idle": "2023-04-20T21:30:42.600844Z",
          "shell.execute_reply.started": "2023-04-20T21:30:42.517507Z",
          "shell.execute_reply": "2023-04-20T21:30:42.598832Z"
        },
        "trusted": true,
        "id": "_botHT6GNDMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can use a lambda function to apply the geocoder to every row in the DataFrame.  (We use a try/except statement to account for the case that the geocoding is unsuccessful.)"
      ],
      "metadata": {
        "id": "QpolOluBNDMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_geocoder(row):\n",
        "    try:\n",
        "        point = geolocator.geocode(row).point\n",
        "        return pd.Series({'Latitude': point.latitude, 'Longitude': point.longitude})\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "universities[['Latitude', 'Longitude']] = universities.apply(lambda x: my_geocoder(x['Name']), axis=1)\n",
        "\n",
        "print(\"{}% of addresses were geocoded!\".format(\n",
        "    (1 - sum(np.isnan(universities[\"Latitude\"])) / len(universities)) * 100))\n",
        "\n",
        "# Drop universities that were not successfully geocoded\n",
        "universities = universities.loc[~np.isnan(universities[\"Latitude\"])]\n",
        "universities = gpd.GeoDataFrame(\n",
        "    universities, geometry=gpd.points_from_xy(universities.Longitude, universities.Latitude))\n",
        "universities.crs = {'init': 'epsg:4326'}\n",
        "universities.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-20T21:30:42.603894Z",
          "iopub.execute_input": "2023-04-20T21:30:42.604624Z"
        },
        "trusted": true,
        "id": "aOZQdpmqNDMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we visualize all of the locations that were returned by the geocoder.  Notice that a few of the locations are certainly inaccurate, as they're not in Europe!"
      ],
      "metadata": {
        "id": "fzip4nyGNDMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a map\n",
        "m = folium.Map(location=[54, 15], tiles='openstreetmap', zoom_start=2)\n",
        "\n",
        "# Add points to the map\n",
        "for idx, row in universities.iterrows():\n",
        "    Marker([row['Latitude'], row['Longitude']], popup=row['Name']).add_to(m)\n",
        "\n",
        "# Display the map\n",
        "m"
      ],
      "metadata": {
        "trusted": true,
        "id": "bFs4bOvENDMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Table joins\n",
        "\n",
        "Now, we'll switch topics and think about how to combine data from different sources.  \n",
        "\n",
        "### Attribute join\n",
        "\n",
        "[You already know](https://www.kaggle.com/residentmario/renaming-and-combining) how to use `pd.DataFrame.join()` to combine information from multiple DataFrames with a shared index.  We refer to this way of joining data (by simpling matching values in the index) as an **attribute join**.\n",
        "\n",
        "When performing an attribute join with a GeoDataFrame, it's best to use the `gpd.GeoDataFrame.merge()`.  To illustrate this, we'll work with a GeoDataFrame `europe_boundaries` containing the boundaries for every country in Europe.  The first five rows of this GeoDataFrame are printed below."
      ],
      "metadata": {
        "id": "OQgiOIDfNDMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "europe = world.loc[world.continent == 'Europe'].reset_index(drop=True)\n",
        "\n",
        "europe_stats = europe[[\"name\", \"pop_est\", \"gdp_md_est\"]]\n",
        "europe_boundaries = europe[[\"name\", \"geometry\"]]"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "id": "0G3IwCp4NDMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "europe_boundaries.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "8uSrrr7BNDMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll join it with a DataFrame `europe_stats` containing the estimated population and gross domestic product (GDP) for each country."
      ],
      "metadata": {
        "id": "VI-PvtM7NDMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "europe_stats.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "NiMEv_CFNDMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do the attribute join in the code cell below.  The `on` argument is set to the column name that is used to match rows in `europe_boundaries` to rows in `europe_stats`."
      ],
      "metadata": {
        "id": "XDI8B-j3NDMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use an attribute join to merge data about countries in Europe\n",
        "europe = europe_boundaries.merge(europe_stats, on=\"name\")\n",
        "europe.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ztTwIFeMNDMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spatial join\n",
        "\n",
        "Another type of join is a **spatial join**.  With a spatial join, we combine GeoDataFrames based on the spatial relationship between the objects in the \"geometry\" columns.  For instance, we already have a GeoDataFrame `universities` containing geocoded addresses of European universities.  \n",
        "\n",
        "Then we can use a spatial join to match each university to its corresponding country.  We do this with `gpd.sjoin()`."
      ],
      "metadata": {
        "id": "TyUMcSOlNDMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use spatial join to match universities to countries in Europe\n",
        "european_universities = gpd.sjoin(universities, europe)\n",
        "\n",
        "# Investigate the result\n",
        "print(\"We located {} universities.\".format(len(universities)))\n",
        "print(\"Only {} of the universities were located in Europe (in {} different countries).\".format(\n",
        "    len(european_universities), len(european_universities.name.unique())))\n",
        "\n",
        "european_universities.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "5qCZ-wzbNDMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The spatial join above looks at the \"geometry\" columns in both GeoDataFrames.  If a Point object from the `universities` GeoDataFrame intersects a Polygon object from the `europe` DataFrame, the corresponding rows are combined and added as a single row of the `european_universities` DataFrame.  Otherwise, countries without a matching university (and universities without a matching country) are omitted from the results.\n",
        "\n",
        "The `gpd.sjoin()` method is customizable for different types of joins, through the `how` and `op` arguments.  For instance, you can do the equivalent of a SQL left (or right) join by setting `how='left'` (or `how='right'`).  We won't go into the details in this course, but you can learn more in [the documentation](https://geopandas.org/en/stable/docs/reference/api/geopandas.sjoin.html).\n",
        "\n",
        "# Your turn\n",
        "\n",
        "**[Use geocoding and table joins](https://www.kaggle.com/kernels/fork/5832170)** to identify suitable locations for the next Starbucks Reserve Roastery."
      ],
      "metadata": {
        "id": "ysxzcu4HNDM0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/geospatial-analysis/discussion) to chat with other learners.*"
      ],
      "metadata": {
        "id": "7EVW-2JaNDM0"
      }
    }
  ]
}